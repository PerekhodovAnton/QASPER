{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9993002099370188,
  "eval_steps": 500,
  "global_step": 714,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.013995801259622114,
      "grad_norm": 1.9015225172042847,
      "learning_rate": 1.25e-06,
      "loss": 2.6929,
      "step": 10
    },
    {
      "epoch": 0.02799160251924423,
      "grad_norm": 1.8304170370101929,
      "learning_rate": 2.6388888888888893e-06,
      "loss": 2.4601,
      "step": 20
    },
    {
      "epoch": 0.04198740377886634,
      "grad_norm": 1.395430564880371,
      "learning_rate": 3.88888888888889e-06,
      "loss": 2.2453,
      "step": 30
    },
    {
      "epoch": 0.05598320503848846,
      "grad_norm": 2.191977024078369,
      "learning_rate": 5.2777777777777785e-06,
      "loss": 2.109,
      "step": 40
    },
    {
      "epoch": 0.06997900629811056,
      "grad_norm": 1.5635490417480469,
      "learning_rate": 6.666666666666667e-06,
      "loss": 1.9165,
      "step": 50
    },
    {
      "epoch": 0.08397480755773268,
      "grad_norm": 1.6183234453201294,
      "learning_rate": 8.055555555555557e-06,
      "loss": 1.7166,
      "step": 60
    },
    {
      "epoch": 0.0979706088173548,
      "grad_norm": 3.1655540466308594,
      "learning_rate": 9.444444444444445e-06,
      "loss": 1.6942,
      "step": 70
    },
    {
      "epoch": 0.11196641007697691,
      "grad_norm": 1.8258119821548462,
      "learning_rate": 9.997845031134992e-06,
      "loss": 1.579,
      "step": 80
    },
    {
      "epoch": 0.12596221133659902,
      "grad_norm": 0.859298586845398,
      "learning_rate": 9.984682503311536e-06,
      "loss": 1.3149,
      "step": 90
    },
    {
      "epoch": 0.13995801259622112,
      "grad_norm": 1.93265962600708,
      "learning_rate": 9.959586126825818e-06,
      "loss": 1.2117,
      "step": 100
    },
    {
      "epoch": 0.15395381385584325,
      "grad_norm": 1.7090352773666382,
      "learning_rate": 9.922615985014887e-06,
      "loss": 1.2955,
      "step": 110
    },
    {
      "epoch": 0.16794961511546536,
      "grad_norm": 1.8902556896209717,
      "learning_rate": 9.873860588245675e-06,
      "loss": 1.4431,
      "step": 120
    },
    {
      "epoch": 0.1819454163750875,
      "grad_norm": 1.5766823291778564,
      "learning_rate": 9.813436662011958e-06,
      "loss": 1.3016,
      "step": 130
    },
    {
      "epoch": 0.1959412176347096,
      "grad_norm": 1.2473903894424438,
      "learning_rate": 9.741488867481377e-06,
      "loss": 1.3449,
      "step": 140
    },
    {
      "epoch": 0.2099370188943317,
      "grad_norm": 1.6681607961654663,
      "learning_rate": 9.65818945516155e-06,
      "loss": 1.2278,
      "step": 150
    },
    {
      "epoch": 0.22393282015395383,
      "grad_norm": 0.8894609808921814,
      "learning_rate": 9.563737852514432e-06,
      "loss": 1.3886,
      "step": 160
    },
    {
      "epoch": 0.23792862141357593,
      "grad_norm": 1.6696697473526,
      "learning_rate": 9.458360186506212e-06,
      "loss": 1.3733,
      "step": 170
    },
    {
      "epoch": 0.25192442267319803,
      "grad_norm": 1.417006492614746,
      "learning_rate": 9.342308742235831e-06,
      "loss": 1.1758,
      "step": 180
    },
    {
      "epoch": 0.26592022393282017,
      "grad_norm": 3.2310237884521484,
      "learning_rate": 9.215861358938191e-06,
      "loss": 1.3251,
      "step": 190
    },
    {
      "epoch": 0.27991602519244224,
      "grad_norm": 1.657987117767334,
      "learning_rate": 9.07932076480812e-06,
      "loss": 1.2485,
      "step": 200
    },
    {
      "epoch": 0.2939118264520644,
      "grad_norm": 1.3635923862457275,
      "learning_rate": 8.933013852237564e-06,
      "loss": 1.3883,
      "step": 210
    },
    {
      "epoch": 0.3079076277116865,
      "grad_norm": 1.1769179105758667,
      "learning_rate": 8.777290895201186e-06,
      "loss": 0.9995,
      "step": 220
    },
    {
      "epoch": 0.3219034289713086,
      "grad_norm": 1.1856268644332886,
      "learning_rate": 8.612524710664012e-06,
      "loss": 1.1499,
      "step": 230
    },
    {
      "epoch": 0.3358992302309307,
      "grad_norm": 1.2200347185134888,
      "learning_rate": 8.439109766018825e-06,
      "loss": 1.1044,
      "step": 240
    },
    {
      "epoch": 0.34989503149055284,
      "grad_norm": 1.0059736967086792,
      "learning_rate": 8.25746123469017e-06,
      "loss": 1.1141,
      "step": 250
    },
    {
      "epoch": 0.363890832750175,
      "grad_norm": 1.559898018836975,
      "learning_rate": 8.06801400216597e-06,
      "loss": 1.1099,
      "step": 260
    },
    {
      "epoch": 0.37788663400979705,
      "grad_norm": 0.9223582744598389,
      "learning_rate": 7.871221624836414e-06,
      "loss": 1.2266,
      "step": 270
    },
    {
      "epoch": 0.3918824352694192,
      "grad_norm": 1.3796088695526123,
      "learning_rate": 7.667555244132749e-06,
      "loss": 1.1948,
      "step": 280
    },
    {
      "epoch": 0.4058782365290413,
      "grad_norm": 1.1165013313293457,
      "learning_rate": 7.457502458565673e-06,
      "loss": 1.1412,
      "step": 290
    },
    {
      "epoch": 0.4198740377886634,
      "grad_norm": 0.9198330640792847,
      "learning_rate": 7.2415661563637506e-06,
      "loss": 1.1148,
      "step": 300
    },
    {
      "epoch": 0.4338698390482855,
      "grad_norm": 1.1545064449310303,
      "learning_rate": 7.020263311506659e-06,
      "loss": 1.3396,
      "step": 310
    },
    {
      "epoch": 0.44786564030790765,
      "grad_norm": 1.5599297285079956,
      "learning_rate": 6.79412374603568e-06,
      "loss": 1.2875,
      "step": 320
    },
    {
      "epoch": 0.46186144156752973,
      "grad_norm": 3.5716686248779297,
      "learning_rate": 6.5636888616046e-06,
      "loss": 1.192,
      "step": 330
    },
    {
      "epoch": 0.47585724282715186,
      "grad_norm": 1.3222615718841553,
      "learning_rate": 6.329510343307801e-06,
      "loss": 1.1834,
      "step": 340
    },
    {
      "epoch": 0.489853044086774,
      "grad_norm": 1.1938406229019165,
      "learning_rate": 6.0921488388887315e-06,
      "loss": 1.169,
      "step": 350
    },
    {
      "epoch": 0.5038488453463961,
      "grad_norm": 1.012316107749939,
      "learning_rate": 5.852172616490875e-06,
      "loss": 1.2116,
      "step": 360
    },
    {
      "epoch": 0.5178446466060181,
      "grad_norm": NaN,
      "learning_rate": 5.634433172680072e-06,
      "loss": 1.2569,
      "step": 370
    },
    {
      "epoch": 0.5318404478656403,
      "grad_norm": 1.6380398273468018,
      "learning_rate": 5.391075876499483e-06,
      "loss": 1.0654,
      "step": 380
    },
    {
      "epoch": 0.5458362491252624,
      "grad_norm": 1.0907789468765259,
      "learning_rate": 5.1467823039718046e-06,
      "loss": 1.0843,
      "step": 390
    },
    {
      "epoch": 0.5598320503848845,
      "grad_norm": 1.1587414741516113,
      "learning_rate": 4.9021373193329775e-06,
      "loss": 1.3699,
      "step": 400
    },
    {
      "epoch": 0.5738278516445067,
      "grad_norm": 1.4056376218795776,
      "learning_rate": 4.657726628136105e-06,
      "loss": 1.0538,
      "step": 410
    },
    {
      "epoch": 0.5878236529041287,
      "grad_norm": 9.523998260498047,
      "learning_rate": 4.414135375011416e-06,
      "loss": 0.9879,
      "step": 420
    },
    {
      "epoch": 0.6018194541637508,
      "grad_norm": 2.0898194313049316,
      "learning_rate": 4.171946742769109e-06,
      "loss": 1.2031,
      "step": 430
    },
    {
      "epoch": 0.615815255423373,
      "grad_norm": 1.4331586360931396,
      "learning_rate": 3.931740556199021e-06,
      "loss": 0.9187,
      "step": 440
    },
    {
      "epoch": 0.6298110566829951,
      "grad_norm": 1.2676291465759277,
      "learning_rate": 3.694091893909746e-06,
      "loss": 1.1697,
      "step": 450
    },
    {
      "epoch": 0.6438068579426172,
      "grad_norm": 1.4581429958343506,
      "learning_rate": 3.459569711530586e-06,
      "loss": 0.9152,
      "step": 460
    },
    {
      "epoch": 0.6578026592022393,
      "grad_norm": 0.8255102634429932,
      "learning_rate": 3.22873547957257e-06,
      "loss": 1.0598,
      "step": 470
    },
    {
      "epoch": 0.6717984604618614,
      "grad_norm": 1.3660730123519897,
      "learning_rate": 3.0021418392096215e-06,
      "loss": 1.1564,
      "step": 480
    },
    {
      "epoch": 0.6857942617214835,
      "grad_norm": 1.064030647277832,
      "learning_rate": 2.7803312791980697e-06,
      "loss": 1.1031,
      "step": 490
    },
    {
      "epoch": 0.6997900629811057,
      "grad_norm": 1.0777322053909302,
      "learning_rate": 2.563834837102115e-06,
      "loss": 1.0085,
      "step": 500
    },
    {
      "epoch": 0.7137858642407278,
      "grad_norm": 1.047784686088562,
      "learning_rate": 2.3531708279346347e-06,
      "loss": 0.9048,
      "step": 510
    },
    {
      "epoch": 0.72778166550035,
      "grad_norm": 1.1010911464691162,
      "learning_rate": 2.1488436032571e-06,
      "loss": 1.0616,
      "step": 520
    },
    {
      "epoch": 0.741777466759972,
      "grad_norm": 1.461024284362793,
      "learning_rate": 1.951342343709456e-06,
      "loss": 1.093,
      "step": 530
    },
    {
      "epoch": 0.7557732680195941,
      "grad_norm": 1.7974053621292114,
      "learning_rate": 1.7611398878607544e-06,
      "loss": 1.0515,
      "step": 540
    },
    {
      "epoch": 0.7697690692792163,
      "grad_norm": 1.1196538209915161,
      "learning_rate": 1.578691600184416e-06,
      "loss": 1.1047,
      "step": 550
    },
    {
      "epoch": 0.7837648705388384,
      "grad_norm": 1.9524449110031128,
      "learning_rate": 1.4044342808682904e-06,
      "loss": 1.1136,
      "step": 560
    },
    {
      "epoch": 0.7977606717984604,
      "grad_norm": 0.898784875869751,
      "learning_rate": 1.23878512006955e-06,
      "loss": 1.1303,
      "step": 570
    },
    {
      "epoch": 0.8117564730580826,
      "grad_norm": 1.682900309562683,
      "learning_rate": 1.0821406991180367e-06,
      "loss": 1.0809,
      "step": 580
    },
    {
      "epoch": 0.8257522743177047,
      "grad_norm": 1.2527059316635132,
      "learning_rate": 9.348760410592855e-07,
      "loss": 1.1371,
      "step": 590
    },
    {
      "epoch": 0.8397480755773268,
      "grad_norm": 1.7995049953460693,
      "learning_rate": 7.973437128103306e-07,
      "loss": 1.2833,
      "step": 600
    },
    {
      "epoch": 0.853743876836949,
      "grad_norm": 1.3138909339904785,
      "learning_rate": 6.698729810778065e-07,
      "loss": 1.0914,
      "step": 610
    },
    {
      "epoch": 0.867739678096571,
      "grad_norm": 0.9340821504592896,
      "learning_rate": 5.527690240591927e-07,
      "loss": 1.0318,
      "step": 620
    },
    {
      "epoch": 0.8817354793561931,
      "grad_norm": 1.1553114652633667,
      "learning_rate": 4.463122008144449e-07,
      "loss": 1.0305,
      "step": 630
    },
    {
      "epoch": 0.8957312806158153,
      "grad_norm": 1.0855581760406494,
      "learning_rate": 3.507573800572328e-07,
      "loss": 1.252,
      "step": 640
    },
    {
      "epoch": 0.9097270818754374,
      "grad_norm": 9.23951244354248,
      "learning_rate": 2.6633332997271277e-07,
      "loss": 1.113,
      "step": 650
    },
    {
      "epoch": 0.9237228831350595,
      "grad_norm": 1.2344309091567993,
      "learning_rate": 1.9324217052268835e-07,
      "loss": 1.1163,
      "step": 660
    },
    {
      "epoch": 0.9377186843946816,
      "grad_norm": 1.306273102760315,
      "learning_rate": 1.31658889549382e-07,
      "loss": 1.0279,
      "step": 670
    },
    {
      "epoch": 0.9517144856543037,
      "grad_norm": 1.335379958152771,
      "learning_rate": 8.173092383633563e-08,
      "loss": 1.0432,
      "step": 680
    },
    {
      "epoch": 0.9657102869139258,
      "grad_norm": 1.2704799175262451,
      "learning_rate": 4.357780612940343e-08,
      "loss": 1.1448,
      "step": 690
    },
    {
      "epoch": 0.979706088173548,
      "grad_norm": 1.2595090866088867,
      "learning_rate": 1.7290878962920587e-08,
      "loss": 1.204,
      "step": 700
    },
    {
      "epoch": 0.9937018894331701,
      "grad_norm": 0.7744536399841309,
      "learning_rate": 2.9330759761692086e-09,
      "loss": 1.109,
      "step": 710
    },
    {
      "epoch": 0.9993002099370188,
      "step": 714,
      "total_flos": 2.6411777463523738e+17,
      "train_loss": 1.2595612094515847,
      "train_runtime": 5231.0774,
      "train_samples_per_second": 1.093,
      "train_steps_per_second": 0.136
    }
  ],
  "logging_steps": 10,
  "max_steps": 714,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 100000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": false,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.6411777463523738e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
